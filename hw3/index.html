<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Henry Li</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://cal-cs184-student.github.io/hw-webpages-sp24-hlxr89/">CS184</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>
<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> 
<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>


<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>
<ul>
<li>Your main report page should be called index.html.</li>
<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>
<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
<li>And again, test your website on the instructional machines early!</li>
</ul>


<p>Here is an example of how to include a simple formula:</p>
<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>

<div>

    <h2 align="middle">Overview</h2>
    <p>
        In this project, I implemented a path tracer that support efficient global illumination rendering with Bounding Volumne
        Hierachy acceleartion, importance sampling, and adaptive sampling. This website will go over steps of constructing the path
        tracer, including Ray generating and Intersection, constructing BVH, Direct Illumination and Indirect illumination with uniform
        Hemisphere sampling, Importance sampling, Russian Roulette termination, and Adaptive sampling.
    </p>
    <br />

    <h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
    <!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
    Explain the triangle intersection algorithm you implemented in your own words.
    Show images with normal shading for a few small .dae files. -->

    <h3>
        Walk through the ray generation and primitive intersection parts of the rendering pipeline.
    </h3>
    <p>
        The path tracer mimic a real camera where all rays are traced from the origin of the camera coordiante sapce passing through
        an (x, y) point on a vitral sensor/image plane to the scene. To generate a ray sample for a pixel (x ,y) on the image plane, we
        first transform the point (x, y) of the image space to a 3D coordinate (x', y', z') in camera space according to the fov of the
        image. We then construct a ray with origin (0, 0, 0) and direction (x', y', z') and performs a camera to world transformation
        on these two vectors to get our ray in the world space. Then the path tracer start with generating those rays for each pixel and
        update the intersected color of the ray to our sample buffer. For supersampling, rays are traced out uniformly random for every
        unit grid of every pixel.
    </p>
    <br />

    <h3>
        Explain the triangle intersection algorithm you implemented in your own words.
    </h3>
    <p>
        To test whether an ray intersect an triangle primitive, I used the Moller Trumbore Algorithm to compute the barycentric
        coordinate of the intersenction point on the plane spanned by the triangle. If any coordinate is negative, we can conclude
        that there is no intersection. Else, we would update the Ray and Intersection object with corresponding intersection time,
        intersected object, normal vector, and bsdf.
    </p>
    <br />

    <h3>
        Show images with normal shading for a few small .dae files.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part1_CBcoil.png" align="middle" width="400px" />
                    <figcaption>CBcoil Scene Normal Shading</figcaption>
                </td>
                <td>
                    <img src="images/Part1_CBempty.png" align="middle" width="400px" />
                    <figcaption>CBempty Scene Normal Shading</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part1_CBgems.png" align="middle" width="400px" />
                    <figcaption>CBgems Scene Normal Shading</figcaption>
                </td>
                <td>
                    <img src="images/Part1_CBspheres_lambertian.png" align="middle" width="400px" />
                    <figcaption>CBspheres Scene Normal Shading</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />


    <h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
    <!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
    Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
    Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

    <h3>
        Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
    </h3>
    <p>
        The BVH structure is similar to a tree strcture, where we split the node to left and right childs, each representing non-overlapped
        set of primitives, with the whole scene being the root node. To split each interior node(non-leaf node), I looked at the mean
        point on all 3 axis, then compared the sum of the bounding boxes' surface area of the two child if I split along each axis to choose
        the axis with the smallest area, which corresponds to a smaller chance of intersection and faster tracing. This process
        is then doen recursively until the node has less than or equal to 5 primitives, where the node become a leaf node and store the primitives.
    </p>

    <h3>
        Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part2_Cow.png" align="middle" width="400px" />
                    <figcaption>Cow Scene Normal Shading</figcaption>
                </td>
                <td>
                    <img src="images/Part2_maxplanck.png" align="middle" width="400px" />
                    <figcaption>Maxplanck Scene Normal Shading</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part2_CBlucy.png" align="middle" width="400px" />
                    <figcaption>CBlucy Scene Normal Shading</figcaption>
                </td>
                <td>
                    <img src="images/Part2_CBbunny.png" align="middle" width="400px" />
                    <figcaption>CBbunny Scene Normal Shading</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />

    <h3>
        Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
    </h3>
    <p>
        Without BVH acceleration, using normal shading and 1 sample per pixel to render a 480*360 pixel image, the above scenes took
        1.2332s(Cow), 13.004s(Maxplankc), 11.2901s(CBbunny), 63.9275s(CBlucy). With BVH acceleration, the same image took
        0.0276s(Cow), 0.0367s(Maxplanck), 0.0249s(CBbunny), 0.0322s(CBlucy). All scenes have shown significant increase in rendering
        speed. The acceleration is benefited from the tree structure of BVH, which reduces the amounmt of intersection checkes from
        O(n) to O(log(n)) where n is the number of primitives in the scene. Thus, scenes like CBlucy wiht more than 100000 primitives
        will benefited a lot from BVH accelearation.

    </p>
    <br />

    <h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
    <!-- Walk through both implementations of the direct lighting function.
    Show some images rendered with both implementations of the direct lighting function.
    Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
    Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

    <h3>
        Walk through both implementations of the direct lighting function.
    </h3>
    <p>
        Direct sampling include two parts, 0 bounce illumination and 1 bounce illumnition. For each ray, both function took in the
        result of BVH intersection test, including an intersected ray and information of the intersected primitive. For
        zero-bounce, the function is simply checking whether the intersected primitive is a light source, and if it is, the function
        returns the light emiision of the light source. For one-bounce illumination, the function will return how much light the primitive
        is reflecting directly from the light source, hence direct illumination. More specifically, the function samples secondary rays
        out from the intersected primitive and perfrom the same intersection tests. The sampling scheme can be uniform over the hemisphere
        or with importance sampling lights, which only samples rays toward the light source. The returning luminance of the given ray will be
        the Monte-Carlo Intergration estimate according to the reflection equation over the light emissions of the secondary rays' interesected primitive.
        The reflection equation includes the bsdf of the given primitive, whose implementation determines the material of the object,
        but this implementation only support diffuse materials.

        <h3>
            Show some images rendered with both implementations of the direct lighting function(64 Camera Ray/pixel, 32 Samples/Area Light, 480*360pxiel).
        </h3>
        <!-- Example of including multiple figures -->
        <div align="middle">
            <table style="width:100%">
                <!-- Header -->
                <tr align="center">
                    <th>
                        <b>Uniform Hemisphere Sampling</b>
                    </th>
                    <th>
                        <b>Light Sampling</b>
                    </th>
                </tr>
                <br />
                <tr align="center">
                    <td>
                        <img src="images/Part3_CBbunny_uniform.png" align="middle" width="400px" />
                        <figcaption>CBbunny Scene Uniform Sampling</figcaption>
                    </td>
                    <td>
                        <img src="images/Part3_CBbunny_importance.png" align="middle" width="400px" />
                        <figcaption>CBbunny Scene Importance Sampling Lights</figcaption>
                    </td>
                </tr>
                <br />
                <tr align="center">
                    <td>
                        <img src="images/Part3_CBspheres_uniform.png" align="middle" width="400px" />
                        <figcaption>CBspheres Lambertian Scene Uniform Sampling</figcaption>
                    </td>
                    <td>
                        <img src="images/Part3_CBspheres_importance.png" align="middle" width="400px" />
                        <figcaption>CBspheres Lambertian Scene Importance Sampling Lights</figcaption>
                    </td>
                </tr>
                <br />
            </table>
        </div>
        <br />

        <h3>
            Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
        </h3>
        <!-- Example of including multiple figures -->
        <div align="middle">
            <table style="width:100%">
                <tr align="center">
                    <td>
                        <img src="images/Part3_1ray.png" align="middle" width="200px" />
                        <figcaption>1 Light Ray (CBspheres_lambertian.dae)</figcaption>
                    </td>
                    <td>
                        <img src="images/Part3_4rays.png" align="middle" width="200px" />
                        <figcaption>4 Light Rays (CBspheres_lambertian.dae)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="images/Part3_16rays.png" align="middle" width="200px" />
                        <figcaption>16 Light Rays (CBspheres_lambertian.dae)</figcaption>
                    </td>
                    <td>
                        <img src="images/Part3_64rays.png" align="middle" width="200px" />
                        <figcaption>64 Light Rays (CBspheres_lambertian.dae)</figcaption>
                    </td>
                </tr>
            </table>
        </div>
    </p>
    <p>
        Starting from only 1 ray per camera pixel, increasing samples per area light will soften the shadows. With 1 sample, the returned value
        of one-bounce illumination is essentially lit or not-lit, leading to noisy spots all around the image. With more samples, there
        are more intermediate levels, allowing half-blocked locations to converge, which result in a smoother, softer shadows.
    </p>
    <br />

    <h3>
        Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
    </h3>
    <p>
        In general, under the same sampling parameters importance sampling will reduce noice of the image, or alternatively it requires
        less samples to converge to the real result. More explicitly, uniform hemisphere sampling causes more noise because of it is more
        random than importance sampling. In an extreme case, for a location that is directly under the light source unblocked, with only
        a few sampled rays from uniform sampling, there are still chances that all sampled ray won't hit the light source, and the function
        will return 0 luminance. This will solve as the sample rate increases for simple probabilistic reason, but it means more runtime, slower
        convergence, and less efficient. With importance sampling, the above example will always return full luminance,
        since it directly samples toward the light source. In the case that the location is half-blocked, importance sampling still have
        higher chance to hit the light source and return the correct result. Therefore, compared to uniform sampling, importance smapling
        generate result with less "variance" and thus less noice.

    </p>
    <br />


    <h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
    <!-- Walk through your implementation of the indirect lighting function.
    Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
    Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
    For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
    Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
    You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

    <h3>
        Walk through your implementation of the indirect lighting function.
    </h3>
    <p>
        As opposed to direct illumination where we expect the secondary ray to direclty hit the light source, indirect light are looking for
        secondary rays that hit the light source after more bounces, or in another word, looking for lights hitting on the given intersected
        primitive that are reflected from other objects. The global illumination are then the sum of lights from zero-bounce to infinite bounce.
        I implement the global illumination by recusion, for each level, we return the one-bounce illumination of the current primitive and
        randomly trace ray out and if it intersects the scene, we recusively call the function on the next intersection until we reach the
        maximum ray depth. However, such an implementation is a biased estimate of the true global illumination since we discard all lights
        after maximum ray depth boucnes. To generate an unbiased estimate, the function is further implemented such that it wil terminate
        randomly with a set proabibility, and the random termination acutally gives the unbiasness property.
    </p>
    <br />

    <h3>
        Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel, 32 samples per area light, max ray depth 5, 480*360 pixels.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part4_CBbunny_1024.png" align="middle" width="400px" />
                    <figcaption>CBbunny.dae</figcaption>
                </td>
                <td>
                    <img src="images/Part4_CBsphere_1024.png" align="middle" width="400px" />
                    <figcaption>CBspheres_lambertian.dae</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />

    <h3>
        Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part4_CBspheres_DirectOnly.png" align="middle" width="400px" />
                    <figcaption>Only direct illumination (CBshpheres_lambertian.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_CBspheres_IndirectOnly.png" align="middle" width="400px" />
                    <figcaption>Only indirect illumination (CBshpheres_lambertian.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />
    <p>
        In the direct illumination image, the ceiling is completely black since they are parallel to the light source, and thus no light
        can directly hit the ceiling. Similarly, the bottom of the spheres are also totally black for the same reason. In the indirect
        illumination only image, the light source is completely black since we ommited the zero-bounce illumination, and the top of the
        spheres are dimmer since most of the light lit on the top are directly from the light source. Meanwhile, the bottom of the spheres
        and the walls are glowing, which are the effects of >1 bounces of lights.
    </p>
    <br />

    <h3>
        For CBbunny.dae, render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag), and isAccumBounces=false. Use 1024 samples per pixel, 8 sample per area light, 480*360pixels.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part4_final0.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_final1.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_final2.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_final3.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_final4.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_final5.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />
    <p>
        In the second bounce, we first see that the ceiling is lit up because the function is returning light that boucne off
        of the wall, the floor, and the bunny to the ceiling. We can also see the bottom of the bunny is lit up by the light
        that boucned off of the floor. In the third bounce, we first notice that it is much dimmer, the bunny is
        dark througout, but the floor on which the bunny sit is a little bit lit up. This is because there are light that
        bounce back from the bottom of the bunny to the floor, which is exactly a third bounce. Compared to rasterization
        techniques that focus more on antialiasing by supersampling, global illumination increases the richness of the
        shading from real world physics.
    </p>
    <br />


    <h3>
        For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, 4, and 5(the -m flag). Use 1024 samples per pixel, 8 sample per area light, 480*360pixels.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part4_m0.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_m1.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_m2.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_m3.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_m4.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_m5.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />
    <p>
        Images are more real as we increase the max ray depth with the most significant improvement at 2 bouces.
        After 2 bounces, the difference of indirect illumination is not easy to see, at least in this scene where
        geometry and light source are fairly simple.
    </p>
    <br />


    <h3>
        For CBbunny.dae, output rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag) using Russian Roulette. Use 1024 samples per pixel, 16 sample per area light, 480*360pixels.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part4_R0.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_R1.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_R2.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_R3.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_R4.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_R100.png" align="middle" width="400px" />
                    <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />
    <p>
       
    </p>
    <br />

    <h3>
        Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays, 5 max ray depth, 480*360pixels.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part4_sample1.png" align="middle" width="400px" />
                    <figcaption>1 sample per pixel (CBspheres_lambertian.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_sample2.png" align="middle" width="400px" />
                    <figcaption>2 samples per pixel (CBspheres_lambertian.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_sample4.png" align="middle" width="400px" />
                    <figcaption>4 samples per pixel (CBspheres_lambertian.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_sample8.png" align="middle" width="400px" />
                    <figcaption>8 samples per pixel (CBspheres_lambertian.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_sample16.png" align="middle" width="400px" />
                    <figcaption>16 samples per pixel (CBspheres_lambertian.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part4_sample64.png" align="middle" width="400px" />
                    <figcaption>64 samples per pixel (CBspheres_lambertian.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part4_sample1024.png" align="middle" width="400px" />
                    <figcaption>1024 samples per pixel (CBspheres_lambertian.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />
    <p>
        For smaller sample size, we see more noices in the image, appeared as white dots. As we increase the sample rate,
        the noice is reduced. This is similar to Part3 where increasing number of samples per area light can reduce noice, 
        increase sample per pixel will accomplish the same. By shooting out more rays for a single pixel and average them, 
        we could reduce the variation of the output, which reduce the noise.
    </p>
    <br />


    <h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
    <!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
    Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

    <h3>
        Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
    </h3>
    <p>
        Adaptive sampling aims to reduce redudant sampling of rays for areas that converges quickly to increase the speed
        of rendering. This implementation of adapitive sampling is basically testing for each pixel whether the result is
        converging as more rays are traced. To test convergence, we are basically looking at a 95% confidence interval
        of the results of samples already traced, and the margin of the interval basically represents the "variance" of
        those samples, if this margin is smaller than a particular threshhold, then we are concluding that the samples are
        converging and stop tracing for this pixel. We perform this test at a particular interval until we reach the 
        given sample size.
    </p>
    <br />

    <h3>
        Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/Part5_bunny2.png" align="middle" width="400px" />
                    <figcaption>Rendered image (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part5_bunnyRate2.png" align="middle" width="400px" />
                    <figcaption>Sample rate image (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/Part5_sphere2.png" align="middle" width="400px" />
                    <figcaption>Rendered image (CBspheres_lambertian.dae)</figcaption>
                </td>
                <td>
                    <img src="images/Part5_sphereRate2.png" align="middle" width="400px" />
                    <figcaption>Sample rate image (CBspheres_lambertian.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br />


</div></body>
</html>
